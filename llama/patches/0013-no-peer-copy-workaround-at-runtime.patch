From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Daniel Hiltgen <daniel@ollama.com>
Date: Sat, 26 Oct 2024 15:10:42 -0700
Subject: [PATCH] no peer copy workaround at runtime

Switch the logic from compile time to runtime for working
around buggy rocm p2p copy on multi-GPU setups.
---
 ggml/src/ggml-cuda.cu | 18 +++++++++---------
 1 file changed, 9 insertions(+), 9 deletions(-)

diff --git a/ggml/src/ggml-cuda.cu b/ggml/src/ggml-cuda.cu
index 6e84af56..d8c5b100 100644
--- a/ggml/src/ggml-cuda.cu
+++ b/ggml/src/ggml-cuda.cu
@@ -531,11 +531,11 @@ GGML_CALL static bool ggml_backend_cuda_buffer_cpy_tensor(ggml_backend_buffer_t
         if (src_ctx->device == dst_ctx->device) {
             CUDA_CHECK(cudaMemcpyAsync(dst->data, src->data, ggml_nbytes(src), cudaMemcpyDeviceToDevice, cudaStreamPerThread));
         } else {
-#ifdef GGML_CUDA_NO_PEER_COPY
+            if (getenv("OLLAMA_NO_PEER_COPY")) {
             return false;
-#else
+            } else {
             CUDA_CHECK(cudaMemcpyPeerAsync(dst->data, dst_ctx->device, src->data, src_ctx->device, ggml_nbytes(src), cudaStreamPerThread));
-#endif
+            }
         }
         CUDA_CHECK(cudaStreamSynchronize(cudaStreamPerThread));
         return true;
@@ -2452,11 +2452,11 @@ GGML_CALL static bool ggml_backend_cuda_cpy_tensor_async(ggml_backend_t backend_
         if (cuda_ctx_src->device == cuda_ctx_dst->device) {
             CUDA_CHECK(cudaMemcpyAsync(dst->data, src->data, ggml_nbytes(dst), cudaMemcpyDeviceToDevice, cuda_ctx_src->stream()));
         } else {
-#ifdef GGML_CUDA_NO_PEER_COPY
+            if (getenv("OLLAMA_NO_PEER_COPY")) {
             return false;
-#else
+            } else {
             CUDA_CHECK(cudaMemcpyPeerAsync(dst->data, cuda_ctx_dst->device, src->data, cuda_ctx_src->device, ggml_nbytes(dst), cuda_ctx_src->stream()));
-#endif
+            }
         }
 
         // record event on src stream after the copy
@@ -3052,9 +3052,9 @@ GGML_CALL static bool ggml_backend_cuda_offload_op(ggml_backend_t backend, const
 }
 
 static ggml_backend_event_t ggml_backend_cuda_event_new(ggml_backend_t backend) {
-#ifdef GGML_CUDA_NO_PEER_COPY
+    if (getenv("OLLAMA_NO_PEER_COPY")) {
     return nullptr;
-#else
+    } else {
     ggml_backend_cuda_context * cuda_ctx = (ggml_backend_cuda_context *)backend->context;
 
     ggml_cuda_set_device(cuda_ctx->device);
@@ -3066,7 +3066,7 @@ static ggml_backend_event_t ggml_backend_cuda_event_new(ggml_backend_t backend)
         /* .backend = */ backend,
         /* .context = */ event,
     };
-#endif
+    }
 }
 
 static void ggml_backend_cuda_event_free(ggml_backend_event_t event) {
